{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e367cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99378e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e2067f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(73512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcaa4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'train.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "with open(r'test.pkl', 'rb') as f:\n",
    "    verify_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566bbdd1",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f27cbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "categories = [row[1] for row in data]\n",
    "\n",
    "class_weights = torch.tensor(compute_class_weight('balanced', classes=[0,1,2,3,4], y=categories)).to(device)\n",
    "print(class_weights)\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "categories_2d = [[category] for category in categories]\n",
    "onehot_encoded = encoder.fit_transform(categories_2d)\n",
    "onehot_encoded_array = onehot_encoded.toarray()\n",
    "\n",
    "data_modified = []\n",
    "targets_modified = []\n",
    "for i in range(len(data)):\n",
    "    row = list(data[i][0])\n",
    "    data_modified.append(row)\n",
    "    row2 = onehot_encoded_array[i]\n",
    "    targets_modified.append(row2)\n",
    "data = [torch.tensor(row).to(torch.float32) for row in data_modified]\n",
    "targets = [torch.tensor(row).to(torch.float32) for row in targets_modified]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588bc85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class VariableLenDataset(Dataset):\n",
    "    def __init__(self, in_data, target):\n",
    "        self.data = [(x, y) for x, y in zip(in_data, target)]      \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        in_data, target = self.data[idx]\n",
    "        return in_data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92566e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "targets = np.array(targets)\n",
    "train_indices = rng.random(len(data)) > 0.3\n",
    "test_indices = ~train_indices\n",
    "train_indices = np.where(train_indices==True)[0]\n",
    "test_indices = np.where(test_indices==True)[0]\n",
    "train_set = VariableLenDataset(data[train_indices], targets[train_indices])\n",
    "test_set = VariableLenDataset(data[test_indices], targets[test_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10b9d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "pad = 0\n",
    "\n",
    "def pad_collate(batch, pad_value=0):\n",
    "    xx, yy = zip(*batch)\n",
    "    x_lens = [len(x) for x in xx]\n",
    "    y_lens = [len(y) for y in yy]\n",
    "\n",
    "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=pad_value)\n",
    "    yy_pad = pad_sequence(yy, batch_first=True, padding_value=pad_value)\n",
    "\n",
    "    return xx_pad, yy_pad, x_lens, y_lens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25a4d26",
   "metadata": {},
   "source": [
    "# LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abc1492",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMRegressor(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers, out_size):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, out_size)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        state = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        return hidden, state\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        x = torch.transpose(x, 0, 1)\n",
    "        all_outputs, hidden = self.lstm(x, hidden)\n",
    "        out = all_outputs[-1]\n",
    "        x = self.fc(out)\n",
    "        return x, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636a6455",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e177aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=10, shuffle=True, collate_fn=pad_collate)\n",
    "test_loader = DataLoader(test_set, batch_size=1, shuffle=False, drop_last=False, collate_fn=pad_collate)\n",
    "model = LSTMRegressor(1, 200, 3, 5).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fun = nn.CrossEntropyLoss(weight=class_weights,reduction='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f952659",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34af0740",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1):\n",
    "    for x, targets, x_len, target_len in train_loader:\n",
    "        x = x.to(device).unsqueeze(2)\n",
    "        targets = targets.to(device)\n",
    "        hidden, state = model.init_hidden(x.size(0))\n",
    "        hidden, state = hidden.to(device), state.to(device) \n",
    "        \n",
    "        preds, _ = model(x, (hidden, state))        \n",
    "        preds = preds.squeeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fun(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}, loss: {loss.item():.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3541a5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    true_preds = 0\n",
    "    num_preds = 0\n",
    "    true_classes_preds = np.array([0,0,0,0,0])\n",
    "    num_classes_preds = np.array([0,0,0,0,0])\n",
    "    for x, targets, x_len, target_len in test_loader:\n",
    "        x = x.to(device).unsqueeze(2)\n",
    "        targets = targets.to(device)\n",
    "        hidden, state = model.init_hidden(x.size(0))\n",
    "        hidden, state = hidden.to(device), state.to(device) \n",
    "        preds, _ = model(x, (hidden, state))\n",
    "        preds = preds.squeeze(1)\n",
    "        preds = (torch.round(preds).int()).long()\n",
    "        if (torch.argmax(preds) == torch.argmax(targets)):\n",
    "            true_preds +=1\n",
    "            true_classes_preds[torch.argmax( \n",
    "                targets).item()]+=1\n",
    "        num_classes_preds[torch.argmax(targets).item()]+=1\n",
    "        num_preds += targets.shape[0]\n",
    "acc = true_preds/num_preds\n",
    "classes_acc = true_classes_preds/num_classes_preds\n",
    "print(\"Number of classes predictions:\",true_classes_preds)\n",
    "print(\"Number of classes labels\",num_classes_preds)\n",
    "print(\"Classes accuracy:\",classes_acc)\n",
    "print(\"Mean:\",statistics.mean(classes_acc))\n",
    "print(\"Euclidean norm:\",np.linalg.norm(np.array(classes_acc))/5)\n",
    "print(\"Accuracy:\",acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778e198e",
   "metadata": {},
   "source": [
    "# Verify data with no labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f6c9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "verify_categories = [row[1] for row in verify_data]\n",
    "\n",
    "\n",
    "verify_data_modified = []\n",
    "for i in range(len(verify_data)):\n",
    "    row = list(verify_data[i])\n",
    "    verify_data_modified.append(row)\n",
    "verify_data = [torch.tensor(row).to(torch.float32) for row in verify_data_modified]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80c78f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class VerifyVariableLenDataset(Dataset):\n",
    "    def __init__(self, in_data):\n",
    "        self.data = in_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        in_data = self.data[idx]\n",
    "        return in_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3fd660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "pad = 0\n",
    "\n",
    "def verify_pad_collate(batch, pad_value=0):\n",
    "    xx = batch\n",
    "    x_lens = [len(x) for x in xx]\n",
    "\n",
    "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=pad_value)\n",
    "    \n",
    "    return xx_pad, x_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67f2bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_data = np.array(verify_data)\n",
    "verify_set = VerifyVariableLenDataset(verify_data)\n",
    "verify_loader = DataLoader(verify_set, batch_size=1, shuffle=False, collate_fn=verify_pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b0f529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    num_classes_preds = np.array([0,0,0,0,0])\n",
    "    for x, x_len in verify_loader:\n",
    "        x = x.to(device).unsqueeze(2)\n",
    "        hidden, state = model.init_hidden(x.size(0))\n",
    "        hidden, state = hidden.to(device), state.to(device) \n",
    "        preds, _ = model(x, (hidden, state))\n",
    "        preds = preds.squeeze(1)\n",
    "        preds = (torch.round(preds).int()).long()\n",
    "        preds = torch.argmax(preds).item()\n",
    "        num_classes_preds[preds]+=1\n",
    "        predictions.append(preds)\n",
    "    print(\"Classes predictions: \",num_classes_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2728e4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"predictions.csv\", 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
