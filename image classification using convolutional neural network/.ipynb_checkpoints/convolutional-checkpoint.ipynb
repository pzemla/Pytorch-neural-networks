{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46520d17",
   "metadata": {
    "id": "46520d17"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bde348a",
   "metadata": {},
   "source": [
    "# data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6be6e4",
   "metadata": {
    "id": "0b6be6e4"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.RandomHorizontalFlip(),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "dataset = torchvision.datasets.ImageFolder(\"/dataset_folder\", transform=transform) \n",
    "trainset,testset = torch.utils.data.random_split(dataset, [0.8,0.2]) \n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = [classess for classess in dataset.class_to_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41800776",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "41800776",
    "outputId": "d49f3669-a124-4842-b771-1efc0b7487b0"
   },
   "outputs": [],
   "source": [
    "#Check number of elements for each class\n",
    "import numpy as np \n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "datahist = [row[1] for row in testloader.dataset]\n",
    "\n",
    "bins = np.arange(-50, 100, 1) \n",
    "\n",
    "plt.xlim([min(datahist)-5, max(datahist)+5])\n",
    "\n",
    "plt.hist(datahist, bins=bins, alpha=0.5)\n",
    "print(classes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9f3d5a",
   "metadata": {},
   "source": [
    "# convolutional neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb26c6f2",
   "metadata": {
    "id": "fb26c6f2"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)  \n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.conv5 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(512)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.LazyLinear(out_features=512)\n",
    "        self.dropout = nn.Dropout(0.6)\n",
    "        self.fc2 = nn.LazyLinear(out_features=num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
    "        x = self.pool(F.relu(self.bn5(self.conv5(x))))\n",
    "        x = torch.flatten(x, 1) \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "num_classes = 50\n",
    "net = Net(num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25c8b87",
   "metadata": {},
   "source": [
    "# parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077d84ce",
   "metadata": {
    "id": "077d84ce"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=0.001)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "if torch.cuda.is_available(): \n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    net.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b9f7d2",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99203fa3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "99203fa3",
    "outputId": "25fe01c3-e2ab-4a97-aa3f-c4de53f5c451"
   },
   "outputs": [],
   "source": [
    "acc1 = 0.0\n",
    "acc2 = 0.0\n",
    "epoch = 0\n",
    "while acc2<90:\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    net.eval()\n",
    "    print('%d epoch loss: %.3f' %(epoch+1 ,  running_loss / 2000))\n",
    "    epoch+=1\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network: %d %%' % (100 * correct / total))\n",
    "    acc1 = acc2\n",
    "    acc2 = 100 * correct / total\n",
    "    if acc2>acc1:\n",
    "        torch.save(\"model.pt\", \"drive/MyDrive/SSNE/Projekt3/train/model.pt\")\n",
    "                   \n",
    "        \n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data    \n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "  \n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname, \n",
    "                                                   accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bH8s2MI_LM6W",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bH8s2MI_LM6W",
    "outputId": "315dd0b9-978f-40e3-9b9f-84c82ee98cd3"
   },
   "outputs": [],
   "source": [
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data    \n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "  \n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname, \n",
    "                                                   accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585baed4",
   "metadata": {},
   "source": [
    "# Verify data with no labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QqhQffhdOy_C",
   "metadata": {
    "id": "QqhQffhdOy_C"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import natsort\n",
    "import PIL\n",
    "class CustomDataSet(Dataset):\n",
    "    def __init__(self, main_dir, transform):\n",
    "        self.main_dir = main_dir\n",
    "        self.transform = transform\n",
    "        all_imgs = os.listdir(main_dir)\n",
    "        self.total_imgs = natsort.natsorted(all_imgs)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.total_imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_loc = os.path.join(self.main_dir, self.total_imgs[idx])\n",
    "        image = PIL.Image.open(img_loc).convert(\"RGB\")\n",
    "        tensor_image = self.transform(image)\n",
    "        return tensor_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HfsvrGFTtiep",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HfsvrGFTtiep",
    "outputId": "d2ae4539-340f-412e-a651-185ab1645482"
   },
   "outputs": [],
   "source": [
    "preds_list=[]\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "dataset = CustomDataSet(\"/test_all\",transform)\n",
    "trainloader = torch.utils.data.DataLoader(dataset,shuffle=False, num_workers=2)\n",
    "filenames = dataset.total_imgs\n",
    "\n",
    "loader = torch.utils.data.DataLoader(dataset,batch_size = len(dataset))\n",
    "dataiter = iter(loader)\n",
    "\n",
    "import csv\n",
    "\n",
    "with torch.no_grad(): \n",
    "        images = next(dataiter)\n",
    "        data_inputs = images.to(device)\n",
    "        preds = net(data_inputs)\n",
    "        preds = preds.squeeze(dim=1)\n",
    "        pred_labels=(torch.argmax(preds,dim=1).view(-1,1)).tolist()\n",
    "        for i in range(len(pred_labels)):\n",
    "          preds_list.append([filenames[i],pred_labels[i][0]])\n",
    "        \n",
    "\n",
    "print(preds_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b3e585",
   "metadata": {
    "id": "13b3e585"
   },
   "outputs": [],
   "source": [
    "from csv import writer\n",
    "with open('/predictions.csv', 'w') as f_object:\n",
    " \n",
    "    writer_object = writer(f_object)\n",
    " \n",
    "    for i in range(0, len(preds_list)):\n",
    "      writer_object.writerow(([preds_list[i][0],preds_list[i][1]]))\n",
    "f_object.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
